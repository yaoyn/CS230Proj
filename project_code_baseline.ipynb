{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFcvASaOdprx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# from: https://www.kaggle.com/sid321axn/step-wise-approach-cnn-model-77-0344-accuracy\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "# np.random.seed(123)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras import backend as K\n",
    "\n",
    "import itertools\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iHHV7azpds6h"
   },
   "outputs": [],
   "source": [
    "# from: https://www.kaggle.com/sid321axn/step-wise-approach-cnn-model-77-0344-accuracy\n",
    "#1. Function to plot model's validation loss and validation accuracy\n",
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 359,
     "status": "ok",
     "timestamp": 1571869902031,
     "user": {
      "displayName": "Yinuo Yao",
      "photoUrl": "",
      "userId": "12766773105987925733"
     },
     "user_tz": 420
    },
    "id": "5StTo6W_lHLG",
    "outputId": "4fcb2bca-1c9e-451c-b598-4baac30c32c6"
   },
   "outputs": [],
   "source": [
    "# from: https://www.kaggle.com/sid321axn/step-wise-approach-cnn-model-77-0344-accuracy\n",
    "# load_type: subset means only portion based on subset_frac is loaded\n",
    "#          : resize means shrinking the images\n",
    "# train, val and test frac is based on the amount of loaded data.\n",
    "path = '/home/ubuntu/'\n",
    "folder = 'skin-cancer-mnist-ham10000'\n",
    "base_dir = os.path.join(path, folder)\n",
    "load_type = 'full_resize' # 'subset', 'subset_resize, 'full', 'full_resize'\n",
    "subset_frac = 0.2\n",
    "train_frac, val_frac, test_frac = 0.9, 0.05, 0.05\n",
    "\n",
    "if (load_type == 'subset' or load_type == 'full'):\n",
    "    img_h = 450\n",
    "    img_w = 600\n",
    "elif (load_type == 'subset_resize' or load_type == 'full_resize'):\n",
    "    img_h = 75\n",
    "    img_w = 100    \n",
    "\n",
    "# Merging images from both folders HAM10000_images_part1.zip and HAM10000_images_part2.zip into one dictionary\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                     for x in glob(os.path.join(base_dir, '*', '*.jpg'))}\n",
    "\n",
    "# This dictionary is useful for displaying more human-friendly labels later on\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'Melanoma',\n",
    "    'bkl': 'Benign keratosis-like lesions ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 344,
     "status": "error",
     "timestamp": 1571869813516,
     "user": {
      "displayName": "Yinuo Yao",
      "photoUrl": "",
      "userId": "12766773105987925733"
     },
     "user_tz": 420
    },
    "id": "Grz9KlUhlWma",
    "outputId": "cd1c9737-d98a-46d2-f97a-76c00a14fde5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>cell_type_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>/home/ubuntu/skin-cancer-mnist-ham10000/HAM100...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>/home/ubuntu/skin-cancer-mnist-ham10000/HAM100...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>/home/ubuntu/skin-cancer-mnist-ham10000/HAM100...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>/home/ubuntu/skin-cancer-mnist-ham10000/HAM100...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>/home/ubuntu/skin-cancer-mnist-ham10000/HAM100...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "                                                path  \\\n",
       "0  /home/ubuntu/skin-cancer-mnist-ham10000/HAM100...   \n",
       "1  /home/ubuntu/skin-cancer-mnist-ham10000/HAM100...   \n",
       "2  /home/ubuntu/skin-cancer-mnist-ham10000/HAM100...   \n",
       "3  /home/ubuntu/skin-cancer-mnist-ham10000/HAM100...   \n",
       "4  /home/ubuntu/skin-cancer-mnist-ham10000/HAM100...   \n",
       "\n",
       "                        cell_type  cell_type_idx  \n",
       "0  Benign keratosis-like lesions               2  \n",
       "1  Benign keratosis-like lesions               2  \n",
       "2  Benign keratosis-like lesions               2  \n",
       "3  Benign keratosis-like lesions               2  \n",
       "4  Benign keratosis-like lesions               2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from: https://www.kaggle.com/sid321axn/step-wise-approach-cnn-model-77-0344-accuracy\n",
    "#Step 3: reading and processing data\n",
    "csv_filename = 'HAM10000_metadata.csv'\n",
    "df_curr = pd.read_csv(os.path.join(base_dir, csv_filename))\n",
    "\n",
    "# Creating New Columns for better readability\n",
    "df_curr['path'] = df_curr['image_id'].map(imageid_path_dict.get)\n",
    "df_curr['cell_type'] = df_curr['dx'].map(lesion_type_dict.get) \n",
    "df_curr['cell_type_idx'] = pd.Categorical(df_curr['cell_type']).codes\n",
    "df_curr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UcTLy5W4oVZE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lesion_id        0\n",
       "image_id         0\n",
       "dx               0\n",
       "dx_type          0\n",
       "age              0\n",
       "sex              0\n",
       "localization     0\n",
       "path             0\n",
       "cell_type        0\n",
       "cell_type_idx    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from: https://www.kaggle.com/sid321axn/step-wise-approach-cnn-model-77-0344-accuracy\n",
    "#Step 4: data cleaning\n",
    "df_curr.isnull().sum()\n",
    "df_curr['age'].fillna((df_curr['age'].mean()), inplace=True)\n",
    "df_curr.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JW5ZHj3ArUf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_resize\n"
     ]
    }
   ],
   "source": [
    "# from: https://www.kaggle.com/sid321axn/step-wise-approach-cnn-model-77-0344-accuracy\n",
    "#Step 6: loading and resizing of images\n",
    "if (load_type == 'subset'):\n",
    "    print('subset')\n",
    "    df_curr = df_curr.sample(frac=subset_frac)\n",
    "    m_curr = df_curr.shape[0] # percentage of total\n",
    "    df_curr['image'] = df_curr['path'].map(lambda x: np.asarray(Image.open(x)))\n",
    "elif (load_type == 'subset_resize'):\n",
    "    print('subset_resize')\n",
    "    df_curr = df_curr.sample(frac=subset_frac)\n",
    "    m_curr = df_curr.shape[0] # percentage of total\n",
    "    df_curr['image'] = df_curr['path'].map(lambda x: np.asarray(Image.open(x).resize((img_w,img_h))))\n",
    "elif (load_type == 'full'):\n",
    "    print(\"full\")\n",
    "    df_curr = df_curr\n",
    "    m_curr = df_curr.shape[0] # percentage of total\n",
    "    df_curr['image'] = df_curr['path'].map(lambda x: np.asarray(Image.open(x)))\n",
    "elif (load_type == 'full_resize'):\n",
    "    print(\"full_resize\")\n",
    "    m_curr = df_curr.shape[0] # percentage of total\n",
    "    df_curr['image'] = df_curr['path'].map(lambda x: np.asarray(Image.open(x).resize((img_w,img_h))))\n",
    "    \n",
    "df_X = df_curr.drop(columns=['cell_type_idx'], axis=1)\n",
    "df_Y = df_curr['cell_type_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ybv5yjUrqP1"
   },
   "outputs": [],
   "source": [
    "# from: https://www.kaggle.com/sid321axn/step-wise-approach-cnn-model-77-0344-accuracy\n",
    "#Step 7: train test split\n",
    "x_train_o, x_test_o, y_train_o, y_test_o = train_test_split(df_X, df_Y, test_size=test_frac, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-16364edc599e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x_train.shape)\n",
    "print(x_train[0].shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_mean_std(data):\n",
    "    std_list = []\n",
    "    for i in range(len(data)):\n",
    "        std_list.append(np.std(data[i]))\n",
    "    mu = np.mean(data)\n",
    "    sig = np.mean(np.asarray(std_list))\n",
    "    return mu, sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from: https://www.kaggle.com/sid321axn/step-wise-approach-cnn-model-77-0344-accuracy\n",
    "# #Step 8: normalization\n",
    "mu_train, sig_train = data_mean_std(x_train_o['image'].tolist())\n",
    "x_train = np.asarray(x_train_o['image'].tolist())\n",
    "x_test = np.asarray(x_test_o['image'].tolist())\n",
    "for i in range(x_train.shape[0]):\n",
    "    x_train[i,:,:,:] = (x_train[i,:,:,:] - mu_train) / sig_train\n",
    "x_test = (x_test - mu_train) / sig_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9HZTR8MBr2oK"
   },
   "outputs": [],
   "source": [
    "# from: https://www.kaggle.com/sid321axn/step-wise-approach-cnn-model-77-0344-accuracy\n",
    "#Step 9: label encoding\n",
    "# Perform one-hot encoding on the labels\n",
    "y_train = to_categorical(y_train_o, num_classes = 7)\n",
    "y_test = to_categorical(y_test_o, num_classes = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hsq7xpIAsBMA"
   },
   "outputs": [],
   "source": [
    "# from: https://www.kaggle.com/sid321axn/step-wise-approach-cnn-model-77-0344-accuracy\n",
    "#Step 10: splitting training and validation split\n",
    "test_frac_train = val_frac / train_frac\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = test_frac_train, random_state = 2)\n",
    "\n",
    "# Reshape image in 3 dimensions (height = 75px, width = 100px , canal = 3)\n",
    "x_train = x_train.reshape(x_train.shape[0], *(img_h, img_w, 3))\n",
    "x_test = x_test.reshape(x_test.shape[0], *(img_h, img_w, 3))\n",
    "x_validate = x_validate.reshape(x_validate.shape[0], *(img_h, img_w, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_qhbKlxCsOIJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1105 07:21:28.590972 140082397665024 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1105 07:21:28.621680 140082397665024 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1105 07:21:28.628526 140082397665024 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1105 07:21:28.664613 140082397665024 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1105 07:21:28.668242 140082397665024 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1105 07:21:28.676228 140082397665024 deprecation.py:506] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 75, 100, 32)       896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 75, 100, 32)       9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 37, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 59200)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               7577728   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 7,588,775\n",
      "Trainable params: 7,588,775\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# from: https://www.kaggle.com/sid321axn/step-wise-approach-cnn-model-77-0344-accuracy\n",
    "#Step 11: model building, CNN\n",
    "# Set the CNN model \n",
    "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "input_shape = (75, 100, 3)\n",
    "num_classes = 7\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',padding = 'Same',input_shape=input_shape))\n",
    "model.add(Conv2D(32,kernel_size=(3, 3), activation='relu',padding = 'Same',))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
    "#model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.40))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# # from: https://www.kaggle.com/sid321axn/step-wise-approach-cnn-model-77-0344-accuracy\n",
    "# #Step 11: model building, CNN\n",
    "# # Set the CNN model \n",
    "# # my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "# input_shape = (img_h, img_w, 3)\n",
    "# num_classes = 7\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',padding = 'Same',input_shape=input_shape))\n",
    "# # model.add(Conv2D(32,kernel_size=(3, 3), activation='relu',padding = 'Same',))\n",
    "# model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "# # model.add(Dropout(0.25))\n",
    "\n",
    "# # model.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# # model.add(Dropout(0.40))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# #model.add(Dropout(0.5))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8IFn3ycpsWDk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1105 07:21:33.595742 140082397665024 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1105 07:21:33.603338 140082397665024 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from: https://www.kaggle.com/sid321axn/step-wise-approach-cnn-model-77-0344-accuracy\n",
    "#Step 12: setting optimizer and annealer\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "\n",
    "# With data augmentation to prevent overfitting \n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ypLpWGLusks7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1105 07:36:32.188235 140082397665024 deprecation.py:323] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "280/280 [==============================] - 124s 444ms/step - loss: 5.5916 - acc: 0.6527 - val_loss: 5.0883 - val_acc: 0.6843\n",
      "Epoch 2/15\n",
      "280/280 [==============================] - 124s 441ms/step - loss: 5.3493 - acc: 0.6681 - val_loss: 5.0883 - val_acc: 0.6843\n",
      "Epoch 3/15\n",
      "280/280 [==============================] - 123s 440ms/step - loss: 5.3434 - acc: 0.6685 - val_loss: 5.0883 - val_acc: 0.6843\n",
      "Epoch 4/15\n",
      "280/280 [==============================] - 123s 439ms/step - loss: 5.3401 - acc: 0.6687 - val_loss: 5.0883 - val_acc: 0.6843\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/15\n",
      "280/280 [==============================] - 123s 438ms/step - loss: 5.3657 - acc: 0.6671 - val_loss: 5.0883 - val_acc: 0.6843\n",
      "Epoch 6/15\n",
      "280/280 [==============================] - 124s 443ms/step - loss: 5.3337 - acc: 0.6691 - val_loss: 5.0883 - val_acc: 0.6843\n",
      "Epoch 7/15\n",
      "280/280 [==============================] - 125s 445ms/step - loss: 5.3526 - acc: 0.6679 - val_loss: 5.0883 - val_acc: 0.6843\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 8/15\n",
      "280/280 [==============================] - 124s 442ms/step - loss: 5.3577 - acc: 0.6676 - val_loss: 5.0883 - val_acc: 0.6843\n",
      "Epoch 9/15\n",
      "280/280 [==============================] - 123s 439ms/step - loss: 5.3298 - acc: 0.6693 - val_loss: 5.0883 - val_acc: 0.6843\n",
      "Epoch 10/15\n",
      "280/280 [==============================] - 123s 439ms/step - loss: 5.3752 - acc: 0.6665 - val_loss: 5.0883 - val_acc: 0.6843\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 11/15\n",
      "280/280 [==============================] - 123s 439ms/step - loss: 5.2999 - acc: 0.6711 - val_loss: 5.0883 - val_acc: 0.6843\n",
      "Epoch 12/15\n",
      "280/280 [==============================] - 123s 441ms/step - loss: 5.3750 - acc: 0.6665 - val_loss: 5.0883 - val_acc: 0.6843\n",
      "Epoch 13/15\n",
      "280/280 [==============================] - 123s 439ms/step - loss: 5.3454 - acc: 0.6684 - val_loss: 5.0883 - val_acc: 0.6843\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 14/15\n",
      "280/280 [==============================] - 123s 439ms/step - loss: 5.3301 - acc: 0.6693 - val_loss: 5.0883 - val_acc: 0.6843\n",
      "Epoch 15/15\n",
      "280/280 [==============================] - 123s 438ms/step - loss: 5.3652 - acc: 0.6671 - val_loss: 5.0883 - val_acc: 0.6843\n"
     ]
    }
   ],
   "source": [
    "# from: https://www.kaggle.com/sid321axn/step-wise-approach-cnn-model-77-0344-accuracy\n",
    "#Step 13: fitting the model\n",
    "\n",
    "# Fit the model\n",
    "epochs = 15 \n",
    "batch_size = 32\n",
    "history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (x_validate,y_validate),\n",
    "                              verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot confusion matrix    \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1scb-J1s5nt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501/501 [==============================] - 1s 3ms/step\n",
      "529/529 [==============================] - 2s 3ms/step\n",
      "501/501 [==============================] - 1s 3ms/step\n",
      "Train: accuracy = 0.115768  ;  loss = 1.887720\n",
      "Validation: accuracy = 0.270321  ;  loss_v = 9.835708\n",
      "Test: accuracy = 0.115768  ;  loss = 1.887720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(87.02500000000006, 0.5, 'Fraction classified incorrectly')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from: https://www.kaggle.com/sid321axn/step-wise-approach-cnn-model-77-0344-accuracy\n",
    "#Step 14: model evaluation\n",
    "loss_t, accuracy_t = model.evaluate(x_test, y_test, verbose=1)\n",
    "loss_v, accuracy_v = model.evaluate(x_validate, y_validate, verbose=1)\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Train: accuracy = %f  ;  loss = %f\" % (accuracy_t, loss_t,))\n",
    "print(\"Validation: accuracy = %f  ;  loss_v = %f\" % (accuracy_v, loss_v))\n",
    "print(\"Test: accuracy = %f  ;  loss = %f\" % (accuracy, loss))\n",
    "model.save(\"model_part1.h5\")\n",
    "\n",
    "#plot_model_history(history)\n",
    "\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(x_validate)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(y_validate,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
    "\n",
    " \n",
    "\n",
    "# plot the confusion matrix\n",
    "label_frac_error = 1 - np.diag(confusion_mtx) / np.sum(confusion_mtx, axis=1)\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(len(label_frac_error))) \n",
    "plt.bar(np.arange(len(label_frac_error)),label_frac_error)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Fraction classified incorrectly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "project_code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
